Does	O
anyone	O
have	O
,	O
or	O
know	O
of	O
,	O
a	O
binary	O
patch	O
generation	O
algorithm	O
implementation	O
in	O
C	O
#	O
?	O
Basically	O
,	O
compare	O
two	O
files	O
(	O
designated	O
old	O
and	O
new	O
)	O
,	O
and	O
produce	O
a	O
patch	O
file	O
that	O
can	O
be	O
used	O
to	O
upgrade	O
the	O
old	O
file	O
to	O
have	O
the	O
same	O
contents	O
as	O
the	O
new	O
file	O
.	O
The	O
implementation	O
would	O
have	O
to	O
be	O
relatively	O
fast	O
,	O
and	O
work	O
with	O
huge	O
files	O
.	O
It	O
should	O
exhibit	O
O	O
(	O
n	O
)	O
or	O
O	O
(	O
logn	O
)	O
runtimes	O
.	O
My	O
own	O
algorithms	O
tend	O
to	O
either	O
be	O
lousy	O
(	O
fast	O
but	O
produce	O
huge	O
patches	O
)	O
or	O
slow	O
(	O
produce	O
small	O
patches	O
but	O
have	O
O	O
(	O
n^2	O
)	O
runtime	O
)	O
.	O
Any	O
advice	O
,	O
or	O
pointers	O
for	O
implementation	O
would	O
be	O
nice	O
.	O
Specifically	O
,	O
the	O
implementation	O
will	O
be	O
used	O
to	O
keep	O
servers	O
in	O
sync	O
for	O
various	O
large	O
datafiles	O
that	O
we	O
have	O
one	O
master	O
server	O
for	O
.	O
When	O
the	O
master	O
server	O
datafiles	O
change	O
,	O
we	O
need	O
to	O
update	O
several	O
off-site	O
servers	O
as	O
well	O
.	O
The	O
most	O
naive	O
algorithm	O
I	O
have	O
made	O
,	O
which	O
only	O
works	O
for	O
files	O
that	O
can	O
be	O
kept	O
in	O
memory	O
,	O
is	O
as	O
follows	O
:	O
Grab	O
the	O
first	O
four	O
bytes	O
from	O
the	O
old	O
file	O
,	O
call	O
this	O
the	O
key	O
Add	O
those	O
bytes	O
to	O
a	O
dictionary	O
,	O
where	O
key	O
-	O
>	O
position	O
,	O
where	O
position	O
is	O
the	O
position	O
where	O
I	O
grabbed	O
those	O
4	O
bytes	O
,	O
0	O
to	O
begin	O
with	O
Skip	O
the	O
first	O
of	O
these	O
four	O
bytes	O
,	O
grab	O
another	O
4	O
(	O
3	O
overlap	O
,	O
1	O
one	O
)	O
,	O
and	O
add	O
to	O
the	O
dictionary	O
the	O
same	O
way	O
Repeat	O
steps	O
1-3	O
for	O
all	O
4-byte	O
blocks	O
in	O
the	O
old	O
file	O
From	O
the	O
start	O
of	O
the	O
new	O
file	O
,	O
grab	O
4	O
bytes	O
,	O
and	O
attempt	O
to	O
look	O
it	O
up	O
in	O
the	O
dictionary	O
If	O
found	O
,	O
find	O
the	O
longest	O
match	O
if	O
there	O
are	O
several	O
,	O
by	O
comparing	O
bytes	O
from	O
the	O
two	O
files	O
Encode	O
a	O
reference	O
to	O
that	O
location	O
in	O
the	O
old	O
file	O
,	O
and	O
skip	O
the	O
matched	O
block	O
in	O
the	O
new	O
file	O
If	O
not	O
found	O
,	O
encode	O
1	O
byte	O
from	O
the	O
new	O
file	O
,	O
and	O
skip	O
it	O
Repeat	O
steps	O
5-8	O
for	O
the	O
rest	O
of	O
the	O
new	O
file	O
This	O
is	O
somewhat	O
like	O
compression	O
,	O
without	O
windowing	O
,	O
so	O
it	O
will	O
use	O
a	O
lot	O
of	O
memory	O
.	O
It	O
is	O
,	O
however	O
,	O
fairly	O
fast	O
,	O
and	O
produces	O
quite	O
small	O
patches	O
,	O
as	O
long	O
as	O
I	O
try	O
to	O
make	O
the	O
codes	O
output	O
minimal	O
.	O
A	O
more	O
memory-efficient	O
algorithm	O
uses	O
windowing	O
,	O
but	O
produces	O
much	O
bigger	O
patch	O
files	O
.	O
There	O
are	O
more	O
nuances	O
to	O
the	O
above	O
algorithm	O
that	O
I	O
skipped	O
in	O
this	O
post	O
,	O
but	O
I	O
can	O
post	O
more	O
details	O
if	O
necessary	O
.	O
I	O
do	O
,	O
however	O
,	O
feel	O
that	O
I	O
need	O
a	O
different	O
algorithm	O
altogether	O
,	O
so	O
improving	O
on	O
the	O
above	O
algorithm	O
is	O
probably	O
not	O
going	O
to	O
get	O
me	O
far	O
enough	O
.	O
Edit	O
#	O
1	O
:	O
Here	O
is	O
a	O
more	O
detailed	O
description	O
of	O
the	O
above	O
algorithm	O
.	O
First	O
,	O
combine	O
the	O
two	O
files	O
,	O
so	O
that	O
you	O
have	O
one	O
big	O
file	O
.	O
Remember	O
the	O
cut-point	O
between	O
the	O
two	O
files	O
.	O
Secondly	O
,	O
do	O
that	O
grab	O
4	O
bytes	O
and	O
add	O
their	O
position	O
to	O
the	O
dictionary	O
step	O
for	O
everything	O
in	O
the	O
whole	O
file	O
.	O
Thirdly	O
,	O
from	O
where	O
the	O
new	O
file	O
starts	O
,	O
do	O
the	O
loop	O
with	O
attempting	O
to	O
locate	O
an	O
existing	O
combination	O
of	O
4	O
bytes	O
,	O
and	O
find	O
the	O
longest	O
match	O
.	O
Make	O
sure	O
we	O
only	O
consider	O
positions	O
from	O
the	O
old	O
file	O
,	O
or	O
from	O
earlier	O
in	O
the	O
new	O
file	O
than	O
we	O
're	O
currently	O
at	O
.	O
This	O
ensures	O
that	O
we	O
can	O
reuse	O
material	O
in	O
both	O
the	O
old	O
and	O
the	O
new	O
file	O
during	O
patch	O
application	O
.	O
Edit	O
#	O
2	O
:	O
Source	O
code	O
to	O
the	O
above	O
algorithm	O
You	O
might	O
get	O
a	O
warning	O
about	O
the	O
certificate	O
having	O
some	O
problems	O
.	O
I	O
do	O
n't	O
know	O
how	O
to	O
resolve	O
that	O
so	O
for	O
the	O
time	O
being	O
just	O
accept	O
the	O
certificate	O
.	O
The	O
source	O
uses	O
lots	O
of	O
other	O
types	O
from	O
the	O
rest	O
of	O
my	O
library	O
so	O
that	O
file	O
is	O
n't	O
all	O
it	O
takes	O
,	O
but	O
that	O
's	O
the	O
algorithm	O
implementation	O
.	O
@	O
lomaxx	O
,	O
I	O
have	O
tried	O
to	O
find	O
a	O
good	O
documentation	O
for	O
the	O
algorithm	O
used	O
in	O
subversion	O
,	O
called	O
xdelta	O
,	O
but	O
unless	O
you	O
already	O
know	O
how	O
the	O
algorithm	O
works	O
,	O
the	O
documents	O
I	O
've	O
found	O
fail	O
to	O
tell	O
me	O
what	O
I	O
need	O
to	O
know	O
.	O
Or	O
perhaps	O
I	O
'm	O
just	O
dense	O
...	O
:	O
)	O
I	O
took	O
a	O
quick	O
peek	O
on	O
the	O
algorithm	O
from	O
that	O
site	O
you	O
gave	O
,	O
and	O
it	O
is	O
unfortunately	O
not	O
usable	O
.	O
A	O
comment	O
from	O
the	O
binary	O
diff	O
file	O
says	O
:	O
Finding	O
an	O
optimal	O
set	O
of	O
differences	O
requires	O
quadratic	O
time	O
relative	O
to	O
the	O
input	O
size	O
,	O
so	O
it	O
becomes	O
unusable	O
very	O
quickly	O
.	O
My	O
needs	O
are	O
n't	O
optimal	O
though	O
,	O
so	O
I	O
'm	O
looking	O
for	O
a	O
more	O
practical	O
solution	O
.	O
Thanks	O
for	O
the	O
answer	O
though	O
,	O
added	O
a	O
bookmark	O
to	O
his	O
utilities	O
if	O
I	O
ever	O
need	O
them	O
.	O
Edit	O
#	O
1	O
:	O
Note	O
,	O
I	O
will	O
look	O
at	O
his	O
code	O
to	O
see	O
if	O
I	O
can	O
find	O
some	O
ideas	O
,	O
and	O
I	O
'll	O
also	O
send	O
him	O
an	O
email	O
later	O
with	O
questions	O
,	O
but	O
I	O
've	O
read	O
that	O
book	O
he	O
references	O
and	O
though	O
the	O
solution	O
is	O
good	O
for	O
finding	O
optimal	O
solutions	O
,	O
it	O
is	O
impractical	O
in	O
use	O
due	O
to	O
the	O
time	O
requirements	O
.	O
Edit	O
#	O
2	O
:	O
I	O
'll	O
definitely	O
hunt	O
down	O
the	O
python	O
xdelta	O
implementation	O
.	O
